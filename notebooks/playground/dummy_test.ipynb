{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emgrep.models.dummy_baseline_model import DummyBaselineModel, DummyBaselineEncoder, DummyBaselineAR\n",
    "from emgrep.datasets.EMGRepDataloader import EMGRepDataloader\n",
    "from emgrep.criterion import CPCCriterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = EMGRepDataloader(\n",
    "    data_path=\"../../data/01_raw\",\n",
    "    train_data=[(1, day, time) for day in range(1, 4) for time in range(1, 3)],\n",
    "    val_data=[(1, 4, time) for time in range(1, 3)],\n",
    "    # test_data=[(1, 5, time) for time in range(1, 3)],\n",
    "    positive_mode=\"none\",\n",
    "    seq_len=3000,\n",
    "    seq_stride=3000,\n",
    "    block_len=300,\n",
    "    block_stride=300,\n",
    "    batch_size=32,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = dataloader.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyBaselineModel(\n",
    "    encoder=DummyBaselineEncoder(),\n",
    "    ar=DummyBaselineAR(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, criterion, optimizer):\n",
    "    size = len(dataloader)\n",
    "    pbar = tqdm(enumerate(dataloader), total=size)\n",
    "    for batch, (emg, stimulus, info) in pbar:\n",
    "        z, c = model(emg.double())\n",
    "        loss = criterion(z, c)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(emg)\n",
    "            pbar.set_description(f\"loss: {loss:>7f}]\")\n",
    "\n",
    "def val_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader)\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for emg, stimulus, info in dataloader:\n",
    "            z, c = model(emg.double())\n",
    "            test_loss += criterion(z, c).item()\n",
    "    test_loss /= size\n",
    "    print(f\"Validation Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "def visualize_embeddings(dataloader, model, epoch=0):\n",
    "    \"\"\"Computes embeddings for the entire dataset and plots them in 2D using umap.\"\"\"\n",
    "    size = len(dataloader)\n",
    "    emg_embeddings = []\n",
    "    label = []\n",
    "    with torch.no_grad():\n",
    "        for emg, stimulus, info in dataloader:\n",
    "            z, c = model(emg.double())\n",
    "            emg_embeddings.append(z.reshape(-1, 128))\n",
    "            label.append(stimulus[:,0,:,-1,0].reshape(-1,1))\n",
    "    emg_embeddings = torch.cat(emg_embeddings, dim=0)\n",
    "    label = torch.cat(label, dim=0)\n",
    "\n",
    "    reducer = umap.UMAP()\n",
    "    embedding = reducer.fit_transform(emg_embeddings)\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], c=label, cmap=\"Spectral\", s=0.1)\n",
    "    plt.title(\"UMAP projection of the EMG embeddings\")\n",
    "    plt.savefig(f\"umap_{epoch}.png\", dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CPCCriterion(3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, criterion, optimizer)\n",
    "    # val_loop(val_dataloader, model, criterion)\n",
    "    visualize_embeddings(val_dataloader, model, t)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicpmlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
